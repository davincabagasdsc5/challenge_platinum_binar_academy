{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4460,"status":"ok","timestamp":1676774671832,"user":{"displayName":"Davinca Rizqy","userId":"05860212563616590890"},"user_tz":-420},"id":"DM7WCpTgh1Na","outputId":"d528d4eb-02c9-40f2-ff1f-9ce8304b0dfc"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n","[nltk_data]     getaddrinfo failed>\n","[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n","[nltk_data]     getaddrinfo failed>\n","[nltk_data] Error loading indonesian: <urlopen error [Errno 11001]\n","[nltk_data]     getaddrinfo failed>\n","[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n","[nltk_data]     getaddrinfo failed>\n"]}],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('indonesian')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","nltk.corpus.stopwords.words('indonesian')\n","from collections import Counter\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, Activation, Dropout, SpatialDropout1D, LSTM\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import  train_test_split\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import  accuracy_score, confusion_matrix, classification_report\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.preprocessing import LabelEncoder\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":951,"status":"ok","timestamp":1676774704777,"user":{"displayName":"Davinca Rizqy","userId":"05860212563616590890"},"user_tz":-420},"id":"dfyqOnawi3wx"},"outputs":[],"source":["df = pd.read_csv(\"train_preprocess.tsv.txt\", sep=\"\\t\", engine=\"python\", names=[\"data\", \"label\"])\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":737,"status":"ok","timestamp":1676774707533,"user":{"displayName":"Davinca Rizqy","userId":"05860212563616590890"},"user_tz":-420},"id":"RNTlwlich1Nz","outputId":"383773f5-5209-4e11-b732-15cad6fc63c3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>data</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10995</th>\n","      <td>tidak kecewa</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>10996</th>\n","      <td>enak rasa masakan nya apalagi kepiting yang me...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>10997</th>\n","      <td>hormati partai-partai yang telah berkoalisi</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>10998</th>\n","      <td>pagi pagi di tol pasteur sudah macet parah , b...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>10999</th>\n","      <td>meskipun sering belanja ke yogya di riau junct...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>11000 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                                                    data     label\n","0      warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n","1      mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n","2      lokasi strategis di jalan sumatera bandung . t...  positive\n","3      betapa bahagia nya diri ini saat unboxing pake...  positive\n","4      duh . jadi mahasiswa jangan sombong dong . kas...  negative\n","...                                                  ...       ...\n","10995                                       tidak kecewa  positive\n","10996  enak rasa masakan nya apalagi kepiting yang me...  positive\n","10997        hormati partai-partai yang telah berkoalisi   neutral\n","10998  pagi pagi di tol pasteur sudah macet parah , b...  negative\n","10999  meskipun sering belanja ke yogya di riau junct...  positive\n","\n","[11000 rows x 2 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":620,"status":"ok","timestamp":1676774710797,"user":{"displayName":"Davinca Rizqy","userId":"05860212563616590890"},"user_tz":-420},"id":"5ihOq4anh1N1","outputId":"7fad2c19-01ea-4d99-8bdf-6270a11309ae"},"outputs":[{"data":{"text/plain":["(11000, 2)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1676774712659,"user":{"displayName":"Davinca Rizqy","userId":"05860212563616590890"},"user_tz":-420},"id":"DhY60IVmh1N3"},"outputs":[],"source":["def cleansing(text):\n","    # Make sentence being lowercase\n","    text = text.lower()\n","\n","    # Remove user, rt, \\n, retweet, \\t, url, xd\n","    pattern_1 = r'(user|retweet|\\\\t|\\\\r|url|xd)'\n","    text = re.sub(pattern_1, '', text)\n","\n","    # Remove mention\n","    pattern_2 = r'@[^\\s]+'\n","    text = re.sub(pattern_2, '', text)\n","\n","    # Remove hashtag\n","    pattern_3 = r'#([^\\s]+)'\n","    text = re.sub(pattern_3, '', text)\n","\n","    # Remove general punctuation, math operation char, etc.\n","    pattern_4 = r'[\\,\\@\\*\\_\\-\\!\\:\\;\\?\\'\\.\\\"\\)\\(\\{\\}\\<\\>\\+\\%\\$\\^\\#\\/\\`\\~\\|\\&\\|]'\n","    text = re.sub(pattern_4, ' ', text)\n","\n","    # Remove single character\n","    pattern_5 = r'\\b\\w{1,3}\\b'\n","    text = re.sub(pattern_5, '', text)\n","\n","    # Remove emoji\n","    pattern_6 = r'\\\\[a-z0-9]{1,5}'\n","    text = re.sub(pattern_6, '', text)\n","\n","    # Remove digit character\n","    pattern_7 = r'\\d+'\n","    text = re.sub(pattern_7, '', text)\n","\n","    # Remove url start with http or https\n","    pattern_8 = r'(https|https:)'\n","    text = re.sub(pattern_8, '', text)\n","\n","    # Remove (\\); ([); (])\n","    pattern_9 = r'[\\\\\\]\\[]'\n","    text = re.sub(pattern_9, '', text)\n","\n","    # Remove character non ASCII\n","    pattern_10 = r'[^\\x00-\\x7f]'\n","    text = re.sub(pattern_10, '', text)\n","\n","    # Remove character non ASCII\n","    pattern_11 = r'(\\\\u[0-9A-Fa-f]+)'\n","    text = re.sub(pattern_11, '', text)\n","\n","    # Remove multiple whitespace\n","    pattern_12 = r'(\\s+|\\\\n)'\n","    text = re.sub(pattern_12, ' ', text)\n","    \n","    # Remove whitespace at the first and end sentences\n","    text = text.rstrip()\n","    text = text.lstrip()\n","    return text\n","\n","indo_stop_words = stopwords.words(\"indonesian\")\n","\n","def remove_stopwords(text):\n","    return ' '.join([word for word in word_tokenize(text) if word not in indo_stop_words])\n","\n","def tokenisasi(text):\n","    tokens = nltk.tokenize.word_tokenize(text)\n","    return tokens\n","\n","def stemming(tokens):\n","    factory = StemmerFactory()\n","    stemmer = factory.create_stemmer()\n","    return ' '.join([stemmer.stem(token) for token in tokens])"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6962,"status":"ok","timestamp":1676774723598,"user":{"displayName":"Davinca Rizqy","userId":"05860212563616590890"},"user_tz":-420},"id":"9HXne__Nh1N8"},"outputs":[],"source":["df_coba = df.applymap(cleansing)\n","#df_coba = df_coba.applymap(remove_stopwords)\n","#df_coba = df_coba.applymap(stemming)\n","df_coba['word_token'] = df_coba['data'].apply(tokenisasi)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":419,"status":"ok","timestamp":1676774726333,"user":{"displayName":"Davinca Rizqy","userId":"05860212563616590890"},"user_tz":-420},"id":"dZTRuKqBb1U2","outputId":"40ba5189-9984-4f94-dbb6-ea645584d761"},"outputs":[],"source":["# Menggabungkan setiap elemen dalam kolom 'word_tokens' menjadi satu string\n","df_coba['string_token'] = df_coba['word_token'].apply(' '.join)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":467,"status":"ok","timestamp":1676774740373,"user":{"displayName":"Davinca Rizqy","userId":"05860212563616590890"},"user_tz":-420},"id":"tjWcV310gYm2"},"outputs":[],"source":["# membuat dictionary mapping\n","#mapping = {'positive': 1, 'neutral': 0, 'negative': 2}"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1676774742287,"user":{"displayName":"Davinca Rizqy","userId":"05860212563616590890"},"user_tz":-420},"id":"oDgG7QJdgd7V"},"outputs":[],"source":["# mengubah nilai pada kolom 'label' dengan method apply\n","#df_coba['label'] = df_coba['label'].apply(lambda x: [mapping[i] for i in x]) --> hanya jika isi kolom 'label' berbentuk list atau array\n","#df_coba['label'] = df_coba['label'].map(mapping)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>data</th>\n","      <th>label</th>\n","      <th>word_token</th>\n","      <th>string_token</th>\n","      <th>label_encode</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>warung dimiliki oleh pengusaha pabrik tahu yan...</td>\n","      <td>positive</td>\n","      <td>[warung, dimiliki, oleh, pengusaha, pabrik, ta...</td>\n","      <td>warung dimiliki oleh pengusaha pabrik tahu yan...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>mohon ulama lurus k mmbri hujjah partai yang h...</td>\n","      <td>neutral</td>\n","      <td>[mohon, ulama, lurus, k, mmbri, hujjah, partai...</td>\n","      <td>mohon ulama lurus k mmbri hujjah partai yang h...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>lokasi strategis jalan sumatera bandung tempat...</td>\n","      <td>positive</td>\n","      <td>[lokasi, strategis, jalan, sumatera, bandung, ...</td>\n","      <td>lokasi strategis jalan sumatera bandung tempat...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>betapa bahagia diri saat unboxing paket barang...</td>\n","      <td>positive</td>\n","      <td>[betapa, bahagia, diri, saat, unboxing, paket,...</td>\n","      <td>betapa bahagia diri saat unboxing paket barang...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>jadi mahasiswa jangan sombong dong kasih kartu...</td>\n","      <td>negative</td>\n","      <td>[jadi, mahasiswa, jangan, sombong, dong, kasih...</td>\n","      <td>jadi mahasiswa jangan sombong dong kasih kartu...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                data     label  \\\n","0  warung dimiliki oleh pengusaha pabrik tahu yan...  positive   \n","1  mohon ulama lurus k mmbri hujjah partai yang h...   neutral   \n","2  lokasi strategis jalan sumatera bandung tempat...  positive   \n","3  betapa bahagia diri saat unboxing paket barang...  positive   \n","4  jadi mahasiswa jangan sombong dong kasih kartu...  negative   \n","\n","                                          word_token  \\\n","0  [warung, dimiliki, oleh, pengusaha, pabrik, ta...   \n","1  [mohon, ulama, lurus, k, mmbri, hujjah, partai...   \n","2  [lokasi, strategis, jalan, sumatera, bandung, ...   \n","3  [betapa, bahagia, diri, saat, unboxing, paket,...   \n","4  [jadi, mahasiswa, jangan, sombong, dong, kasih...   \n","\n","                                        string_token  label_encode  \n","0  warung dimiliki oleh pengusaha pabrik tahu yan...             2  \n","1  mohon ulama lurus k mmbri hujjah partai yang h...             1  \n","2  lokasi strategis jalan sumatera bandung tempat...             2  \n","3  betapa bahagia diri saat unboxing paket barang...             2  \n","4  jadi mahasiswa jangan sombong dong kasih kartu...             0  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["data            object\n","label           object\n","word_token      object\n","string_token    object\n","label_encode     int32\n","dtype: object\n"]}],"source":["le = LabelEncoder()\n","\n","df_coba['label_encode'] = le.fit_transform(df_coba['label'])\n","\n","display(df_coba.head())\n","\n","print(df_coba.dtypes)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":433,"status":"ok","timestamp":1676774748381,"user":{"displayName":"Davinca Rizqy","userId":"05860212563616590890"},"user_tz":-420},"id":"T83xw7xAgJge","outputId":"28cca3f7-d7d1-431e-e251-d49ed960b241"},"outputs":[{"data":{"text/plain":["data            0\n","label           0\n","word_token      0\n","string_token    0\n","label_encode    0\n","dtype: int64"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df_coba.isna().sum()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# CNN"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n","275/275 [==============================] - 43s 144ms/step - loss: 0.5730 - accuracy: 0.7561 - val_loss: 0.4144 - val_accuracy: 0.8368\n","Epoch 2/2\n","275/275 [==============================] - 40s 144ms/step - loss: 0.3026 - accuracy: 0.8883 - val_loss: 0.3766 - val_accuracy: 0.8623\n","69/69 - 1s - loss: 0.3766 - accuracy: 0.8623 - 1s/epoch - 17ms/step\n","Test accuracy: 0.8622727394104004\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Load data\n","#data = pd.read_csv(\"train_preprocess.tsv.txt\", sep=\"\\t\", engine=\"python\", names=[\"data\", \"label\"])\n","sentences = df_coba['word_token'].to_list()\n","labels = df_coba['label_encode'].to_list()\n","\n","\n","\n","# Convert labels to numeric values\n","#label_dict = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n","#labels = np.array([label_dict[label] for label in labels])\n","#labels = np.array([labels])\n","\n","# Tokenize data\n","tokenizer = tf.keras.preprocessing.text.Tokenizer()\n","tokenizer.fit_on_texts(sentences)\n","word_index = tokenizer.word_index\n","vocab_size = len(word_index) + 1\n","sequences = tokenizer.texts_to_sequences(sentences)\n","padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=250)\n","\n","# Split data into training and testing sets\n","X_train, X_test, Y_train, Y_test = train_test_split(padded_sequences, labels, test_size=0.2)\n","\n","# One-hot encode the labels\n","Y_train = tf.keras.utils.to_categorical(Y_train, 3)\n","Y_test = tf.keras.utils.to_categorical(Y_test, 3)\n","\n","# Define the model architecture\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=128, input_length=250),\n","    tf.keras.layers.Conv1D(64, 5, activation='relu'),\n","    tf.keras.layers.MaxPooling1D(5),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(3, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train the model\n","batch_size = 32\n","epochs = 2\n","history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, Y_test))\n","\n","# Evaluate the model on test set\n","test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=2)\n","print(\"Test accuracy:\", test_acc)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"QGmGOCLZfgke"},"outputs":[],"source":["# mengubah nilai pada kolom 'label' menjadi integer\n","#df_coba['label'] = df_coba['label'].apply(lambda x: x[0]).astype(int)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["#text = df_coba['word_token'].tolist()\n","#print(len(text))"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["#token = Tokenizer()\n","#token.fit_on_texts(text)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["#df_coba['word_to_index'] = token.texts_to_sequences(text)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Save CNN Model"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["model.save(\"sentiment_analysis_model_CNN_challenge.h5\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## preprocessing tambahan untuk LSTM"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["df_copy = df_coba.copy()\n","df_copy.drop(columns=[\"data\",\"label\"], inplace=True)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word_token</th>\n","      <th>string_token</th>\n","      <th>label_encode</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[warung, dimiliki, oleh, pengusaha, pabrik, ta...</td>\n","      <td>warung dimiliki oleh pengusaha pabrik tahu yan...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[mohon, ulama, lurus, k, mmbri, hujjah, partai...</td>\n","      <td>mohon ulama lurus k mmbri hujjah partai yang h...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[lokasi, strategis, jalan, sumatera, bandung, ...</td>\n","      <td>lokasi strategis jalan sumatera bandung tempat...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[betapa, bahagia, diri, saat, unboxing, paket,...</td>\n","      <td>betapa bahagia diri saat unboxing paket barang...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[jadi, mahasiswa, jangan, sombong, dong, kasih...</td>\n","      <td>jadi mahasiswa jangan sombong dong kasih kartu...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10995</th>\n","      <td>[tidak, kecewa]</td>\n","      <td>tidak kecewa</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>10996</th>\n","      <td>[enak, rasa, masakan, apalagi, kepiting, yang,...</td>\n","      <td>enak rasa masakan apalagi kepiting yang menyen...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>10997</th>\n","      <td>[hormati, partai, partai, yang, telah, berkoal...</td>\n","      <td>hormati partai partai yang telah berkoalisi</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10998</th>\n","      <td>[pagi, pagi, pasteur, sudah, macet, parah, bik...</td>\n","      <td>pagi pagi pasteur sudah macet parah bikin jeng...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10999</th>\n","      <td>[meskipun, sering, belanja, yogya, riau, junct...</td>\n","      <td>meskipun sering belanja yogya riau junction ta...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>11000 rows Ã— 3 columns</p>\n","</div>"],"text/plain":["                                              word_token  \\\n","0      [warung, dimiliki, oleh, pengusaha, pabrik, ta...   \n","1      [mohon, ulama, lurus, k, mmbri, hujjah, partai...   \n","2      [lokasi, strategis, jalan, sumatera, bandung, ...   \n","3      [betapa, bahagia, diri, saat, unboxing, paket,...   \n","4      [jadi, mahasiswa, jangan, sombong, dong, kasih...   \n","...                                                  ...   \n","10995                                    [tidak, kecewa]   \n","10996  [enak, rasa, masakan, apalagi, kepiting, yang,...   \n","10997  [hormati, partai, partai, yang, telah, berkoal...   \n","10998  [pagi, pagi, pasteur, sudah, macet, parah, bik...   \n","10999  [meskipun, sering, belanja, yogya, riau, junct...   \n","\n","                                            string_token  label_encode  \n","0      warung dimiliki oleh pengusaha pabrik tahu yan...             2  \n","1      mohon ulama lurus k mmbri hujjah partai yang h...             1  \n","2      lokasi strategis jalan sumatera bandung tempat...             2  \n","3      betapa bahagia diri saat unboxing paket barang...             2  \n","4      jadi mahasiswa jangan sombong dong kasih kartu...             0  \n","...                                                  ...           ...  \n","10995                                       tidak kecewa             2  \n","10996  enak rasa masakan apalagi kepiting yang menyen...             2  \n","10997        hormati partai partai yang telah berkoalisi             1  \n","10998  pagi pagi pasteur sudah macet parah bikin jeng...             0  \n","10999  meskipun sering belanja yogya riau junction ta...             2  \n","\n","[11000 rows x 3 columns]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["df_copy"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# NAIVE BAYES"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["vectorizer = CountVectorizer()\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(df_copy['string_token'], df_copy['label_encode'], train_size=0.8, random_state=42)\n","X_train = vectorizer.fit_transform(X_train)\n","X_test = vectorizer.transform(X_test)\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["nb = MultinomialNB() # Panggil MODEL NB\n","nb.fit(X_train, Y_train) # Training data\n","Y_pred = nb.predict(X_test) # Prediksi data X_test\n"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 528,   69,  116],\n","       [   5,  135,    7],\n","       [ 147,   35, 1158]], dtype=int64)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["confusion_matrix(Y_pred, Y_test)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.78      0.74      0.76       713\n","           1       0.56      0.92      0.70       147\n","           2       0.90      0.86      0.88      1340\n","\n","    accuracy                           0.83      2200\n","   macro avg       0.75      0.84      0.78      2200\n","weighted avg       0.84      0.83      0.83      2200\n","\n"]}],"source":["print(classification_report(Y_pred, Y_test))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# LSTM"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["df_copy['word_token'] = df_copy['word_token'].to_list()\n","df_copy['label_encode'] = df_copy['label_encode'].to_list()\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 15763 unique tokens.\n","Shape of data tensor: (11000, 250)\n"]}],"source":["MAX_NB_WORDS = 50000\n","MAX_SEQUENCE_LENGTH = 250\n","EMBEDDING_DIM = 100\n","tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+.,-./:;<=>?@[\\]^_`{|}~', lower=True)\n","tokenizer.fit_on_texts(df_copy['word_token'].values)\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))\n","\n","X = tokenizer.texts_to_sequences(df_copy['word_token'].values)\n","X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n","print('Shape of data tensor:', X.shape)\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of label tensor: (11000, 3)\n"]}],"source":["Y = pd.get_dummies(df_copy['label_encode']).values\n","print('Shape of label tensor:', Y.shape)\n"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(9900, 250) (9900, 3)\n","(1100, 250) (1100, 3)\n"]}],"source":["X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.10, random_state=42)\n","print(X_train.shape, Y_train.shape)\n","print(X_test.shape, Y_test.shape)"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n","140/140 [==============================] - 180s 1s/step - loss: 0.6075 - accuracy: 0.7536 - val_loss: 0.4370 - val_accuracy: 0.8192\n","Epoch 2/2\n","140/140 [==============================] - 173s 1s/step - loss: 0.2898 - accuracy: 0.8984 - val_loss: 0.3519 - val_accuracy: 0.8717\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x1caf178ca90>"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["model = Sequential()\n","model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n","model.add(SpatialDropout1D(0.2))\n","model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(3, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","epochs = 2\n","batch_size = 64\n","\n","model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["35/35 [==============================] - 7s 122ms/step\n"]},{"data":{"text/plain":["(1100, 3)"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["Y_pred = model.predict(X_test)\n","Y_pred.shape"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 1 2 ... 2 2 0]\n"]}],"source":["#from mlxtend.preprocessing import one_hote\n","#result = np.where(Y_pred[0]==np.amax(Y_pred[0]))\n","#one_hot(result[0])\n","\n","Y_pred_labels = np.argmax(Y_pred, axis=1)\n","print(Y_pred_labels)"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 88.00%\n"]}],"source":["Y_pred_classes = np.argmax(Y_pred, axis=1)\n","Y_test_classes = np.argmax(Y_test, axis=1)\n","accuracy = accuracy_score(Y_test_classes, Y_pred_classes)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.81      0.88      0.84       342\n","           1       0.85      0.78      0.81       116\n","           2       0.93      0.90      0.91       642\n","\n","    accuracy                           0.88      1100\n","   macro avg       0.86      0.85      0.86      1100\n","weighted avg       0.88      0.88      0.88      1100\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","\n","Y_pred_classes = np.argmax(Y_pred, axis=1)\n","Y_test_classes = np.argmax(Y_test, axis=1)\n","print(classification_report(Y_test_classes, Y_pred_classes))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Save LSTM Model"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["model.save(\"sentiment_analysis_model_LSTM_challenge.h5\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Cara Menggunakan model kembali dengan load model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["344/344 [==============================] - 34s 97ms/step\n"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import pandas as pd\n","from keras.preprocessing.text import Tokenizer\n","from keras.models import load_model\n","\n","# load data baru\n","df_new = pd.read_csv(\"train_preprocess.tsv.txt\", sep=\"\\t\", engine=\"python\", names=[\"data\", \"label\"])\n","df_new = df_new.applymap(cleansing)\n","df_new = df_new.applymap(remove_stopwords)\n","\n","# drop kolom label\n","df_new.drop(columns=['label'], inplace=True)\n","\n","# lakukan preprocessing pada data baru\n","tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n","tokenizer.fit_on_texts(df_new['data'].values)\n","X_new = tokenizer.texts_to_sequences(df_new['data'].values)\n","X_new = pad_sequences(X_new, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","loaded_model = load_model(\"D:\\github branch davinca\\challenge_platinum_binar_academy\\sentiment_analysis_model_challenge.h5\")\n","\n","# lakukan prediksi pada data baru\n","Y_prob = loaded_model.predict(X_new)\n","Y_pred = Y_prob.argmax(axis=-1)\n","\n","# konversi nilai prediksi menjadi label sentimen\n","labels = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n","df_new[\"label_sentimen\"] = [labels[pred] for pred in Y_pred]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>data</th>\n","      <th>label_sentimen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>warung dimiliki pengusaha pabrik puluhan terke...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>mohon ulama lurus k mmbri hujjah partai diwlh ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>lokasi strategis jalan sumatera bandung nyaman...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>betapa bahagia unboxing paket barang bagus men...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>mahasiswa sombong kasih kartu kuning belajar u...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10995</th>\n","      <td>kecewa</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>10996</th>\n","      <td>enak masakan kepiting menyenangkan memilih kep...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>10997</th>\n","      <td>hormati partai partai berkoalisi</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>10998</th>\n","      <td>pagi pagi pasteur macet parah bikin jengkel</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>10999</th>\n","      <td>belanja yogya riau junction kali lihat foodlif...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>11000 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                                                    data label_sentimen\n","0      warung dimiliki pengusaha pabrik puluhan terke...       positive\n","1      mohon ulama lurus k mmbri hujjah partai diwlh ...       positive\n","2      lokasi strategis jalan sumatera bandung nyaman...       positive\n","3      betapa bahagia unboxing paket barang bagus men...       positive\n","4      mahasiswa sombong kasih kartu kuning belajar u...       negative\n","...                                                  ...            ...\n","10995                                             kecewa       positive\n","10996  enak masakan kepiting menyenangkan memilih kep...       positive\n","10997                   hormati partai partai berkoalisi       positive\n","10998        pagi pagi pasteur macet parah bikin jengkel       negative\n","10999  belanja yogya riau junction kali lihat foodlif...       positive\n","\n","[11000 rows x 2 columns]"]},"execution_count":35,"metadata":{},"output_type":"execute_result"},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["df_new\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Cara menggunakan kembali model yang telah dibuat (load model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["412/412 [==============================] - 43s 103ms/step\n"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import pandas as pd\n","from keras.preprocessing.text import Tokenizer\n","from keras.models import load_model\n","\n","# load data baru\n","df_new = pd.read_csv(\"original_data.csv\", encoding='latin-1')\n","df_new['Tweet'] = df_new['Tweet'].apply(cleansing)\n","df_new['Tweet'] = df_new['Tweet'].apply(remove_stopwords)\n","\n","# lakukan preprocessing pada data baru\n","tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n","tokenizer.fit_on_texts(df_new['Tweet'].values)\n","X_new = tokenizer.texts_to_sequences(df_new['Tweet'].values)\n","X_new = pad_sequences(X_new, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","loaded_model = load_model(\"D:\\github branch davinca\\challenge_platinum_binar_academy\\sentiment_analysis_model_challenge.h5\")\n","\n","# lakukan prediksi pada data baru\n","Y_prob = loaded_model.predict(X_new)\n","Y_pred = Y_prob.argmax(axis=-1)\n","\n","# konversi nilai prediksi menjadi label sentimen\n","labels = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n","df_new[\"label\"] = [labels[pred] for pred in Y_pred]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Tweet</th>\n","      <th>HS</th>\n","      <th>Abusive</th>\n","      <th>HS_Individual</th>\n","      <th>HS_Group</th>\n","      <th>HS_Religion</th>\n","      <th>HS_Race</th>\n","      <th>HS_Physical</th>\n","      <th>HS_Gender</th>\n","      <th>HS_Other</th>\n","      <th>HS_Weak</th>\n","      <th>HS_Moderate</th>\n","      <th>HS_Strong</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>disaat cowok berusaha melacak perhatian lantas...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>telat ngasih edan sarap bergaul cigax jifla ca...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>kadang berfikir percaya tuhan jatuh berkali ka...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>matamu sipit diliat</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>kaum cebong kapir udah keliatan dongoknya dong...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13164</th>\n","      <td>13164</td>\n","      <td>ngomong ndasmu congor sekate anjyng</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>13165</th>\n","      <td>13165</td>\n","      <td>kasur enak kunyuk</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>13166</th>\n","      <td>13166</td>\n","      <td>hati hati bisu bosan huft</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>13167</th>\n","      <td>13167</td>\n","      <td>real mudah terdeteksi terkubur dahsyat ledakan...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>13168</th>\n","      <td>13168</td>\n","      <td>situ ngasih foto kutil onta</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13169 rows Ã— 15 columns</p>\n","</div>"],"text/plain":["       Unnamed: 0                                              Tweet  HS  \\\n","0               0  disaat cowok berusaha melacak perhatian lantas...   1   \n","1               1  telat ngasih edan sarap bergaul cigax jifla ca...   0   \n","2               2  kadang berfikir percaya tuhan jatuh berkali ka...   0   \n","3               3                                matamu sipit diliat   0   \n","4               4  kaum cebong kapir udah keliatan dongoknya dong...   1   \n","...           ...                                                ...  ..   \n","13164       13164                ngomong ndasmu congor sekate anjyng   1   \n","13165       13165                                  kasur enak kunyuk   0   \n","13166       13166                          hati hati bisu bosan huft   0   \n","13167       13167  real mudah terdeteksi terkubur dahsyat ledakan...   0   \n","13168       13168                        situ ngasih foto kutil onta   1   \n","\n","       Abusive  HS_Individual  HS_Group  HS_Religion  HS_Race  HS_Physical  \\\n","0            1              1         0            0        0            0   \n","1            1              0         0            0        0            0   \n","2            0              0         0            0        0            0   \n","3            0              0         0            0        0            0   \n","4            1              0         1            1        0            0   \n","...        ...            ...       ...          ...      ...          ...   \n","13164        1              1         0            0        0            1   \n","13165        1              0         0            0        0            0   \n","13166        0              0         0            0        0            0   \n","13167        0              0         0            0        0            0   \n","13168        1              1         0            0        0            0   \n","\n","       HS_Gender  HS_Other  HS_Weak  HS_Moderate  HS_Strong     label  \n","0              0         1        1            0          0  positive  \n","1              0         0        0            0          0  positive  \n","2              0         0        0            0          0  positive  \n","3              0         0        0            0          0  negative  \n","4              0         0        0            1          0  positive  \n","...          ...       ...      ...          ...        ...       ...  \n","13164          0         0        1            0          0   neutral  \n","13165          0         0        0            0          0   neutral  \n","13166          0         0        0            0          0  positive  \n","13167          0         0        0            0          0  positive  \n","13168          0         1        1            0          0  negative  \n","\n","[13169 rows x 15 columns]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["df_new"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweet</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>disaat cowok berusaha melacak perhatian lantas...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>telat ngasih edan sarap bergaul cigax jifla ca...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>kadang berfikir percaya tuhan jatuh berkali ka...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>matamu sipit diliat</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>kaum cebong kapir udah keliatan dongoknya dong...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               Tweet     Label\n","0  disaat cowok berusaha melacak perhatian lantas...  positive\n","1  telat ngasih edan sarap bergaul cigax jifla ca...  positive\n","2  kadang berfikir percaya tuhan jatuh berkali ka...  positive\n","3                                matamu sipit diliat  negative\n","4  kaum cebong kapir udah keliatan dongoknya dong...  positive"]},"execution_count":38,"metadata":{},"output_type":"execute_result"},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["df_tweet_predict = pd.DataFrame({\"Tweet\": df_new['Tweet'],\n","                           \"Label\": df_new['label']\n","                        })\n","df_tweet_predict.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweet</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>disaat cowok berusaha melacak perhatian lantas...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>telat ngasih edan sarap bergaul cigax jifla ca...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>kadang berfikir percaya tuhan jatuh berkali ka...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>matamu sipit diliat</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>kaum cebong kapir udah keliatan dongoknya dong...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13164</th>\n","      <td>ngomong ndasmu congor sekate anjyng</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>13165</th>\n","      <td>kasur enak kunyuk</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>13166</th>\n","      <td>hati hati bisu bosan huft</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>13167</th>\n","      <td>real mudah terdeteksi terkubur dahsyat ledakan...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>13168</th>\n","      <td>situ ngasih foto kutil onta</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13169 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                                                   Tweet     Label\n","0      disaat cowok berusaha melacak perhatian lantas...  positive\n","1      telat ngasih edan sarap bergaul cigax jifla ca...  positive\n","2      kadang berfikir percaya tuhan jatuh berkali ka...  positive\n","3                                    matamu sipit diliat  negative\n","4      kaum cebong kapir udah keliatan dongoknya dong...  positive\n","...                                                  ...       ...\n","13164                ngomong ndasmu congor sekate anjyng   neutral\n","13165                                  kasur enak kunyuk   neutral\n","13166                          hati hati bisu bosan huft  positive\n","13167  real mudah terdeteksi terkubur dahsyat ledakan...  positive\n","13168                        situ ngasih foto kutil onta  negative\n","\n","[13169 rows x 2 columns]"]},"execution_count":39,"metadata":{},"output_type":"execute_result"},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["df_tweet_predict\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["array(['positive', 'negative', 'neutral'], dtype=object)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["df_tweet_predict['Label'].unique()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# --batas akhir modelling CNN dan LSTM--"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# kode-kode dibawah ini sudah tidak dipakai"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["#x = df_copy.iloc[:,1] # parameter (features)\n","#y = df_copy.iloc[:,0] # targeted"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["#x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.7)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["#print(x_train.shape)  # Output: (n_data_points, n_features)\n","#print(y_train.shape)  # Output: (n_data_points,)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["#x_train_dtype = np.array(x_train).dtype\n","#print(x_train_dtype)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["#y_train_dtype = np.array(y_train).dtype\n","#print(y_train_dtype)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["#MAX_SEQUENCE_LENGTH = 100\n","\n","# Lakukan padding pada setiap data input\n","#x_train = pad_sequences(x_train, maxlen=MAX_SEQUENCE_LENGTH)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["#MAX_SEQUENCE_LENGTH = 100\n","\n","# Lakukan padding pada setiap data input\n","#x_test = pad_sequences(x_test, maxlen=MAX_SEQUENCE_LENGTH)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["#x_train = np.array(x_train, dtype=np.int64)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(50, 25, 10), max_iter=500,\n","              random_state=1, solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(50, 25, 10), max_iter=500,\n","              random_state=1, solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"],"text/plain":["MLPClassifier(alpha=1e-05, hidden_layer_sizes=(50, 25, 10), max_iter=500,\n","              random_state=1, solver='lbfgs')"]},"execution_count":30,"metadata":{},"output_type":"execute_result"},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 25, 10), random_state=1, max_iter=500)\n","\n","clf.fit(X_train, Y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["#y_pred = clf.predict(x_test)\n","#y_pred # sbetulnya masih termasuk error ini "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["0.8145454545454546"]},"execution_count":32,"metadata":{},"output_type":"execute_result"},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["accuracy_score(Y_test, Y_pred)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ebfc0a8d552866b0d59eba665220a57de3bc06f3ac643b8bef38dd8f66781fdd"}}},"nbformat":4,"nbformat_minor":0}
